# Student t distribution mixture model

library(nimble)
source("finite_mixture.R")
# Define the t-mixture model code
t_mixture_code <- nimbleCode({
  for (i in 1:N) {
    # Latent variable indicating the mixture component
    z[i] ~ dcat(w[1:K]) 
    
    # Observations modeled as a Student-t distribution
    y[i] ~ dt(mu[z[i]], tau[z[i]], nu[z[i]])  # Student-t distribution with unknown degrees of freedom
  }
  
  for (k in 1:K) {
    # Priors for component-specific means and precisions (tau = 1/sigma^2)
    mu[k] ~ dnorm(0, 0.01)
    tau[k] <- dgamma(1, 1)  # Precision
    
    # Metropolis-Hastings for degrees of freedom (νk)
    nu[k] ~ dexp(0.1)  # Prior for νk (degrees of freedom)
  }
  
  # Dirichlet prior for the weights
  w[1:K] ~ ddirch(alpha[1:K])
})

require(bmixture)
# Specifying the Data
# N <- 60  # Number of observations
K <- 3    # Number of mixture components
# weights <- c(1/3,1/3,1/3)
# df <- c(1,3,2)
# mu <- c(0,5,-5)
# sd <- c(1 , 4, 2.5)

weights <- 1
df <- 3
mu <- 6
sd <- 2
set.seed(123)
# 

N <- 100
mu <- 3
sigma <- 1.15
y <- rnorm(N, mu, sigma)

prop_outliers <- 0.05
shift <- 15
n_outliers <- round(N*prop_outliers)
ind_outliers<- sample(1:N, size = n_outliers)
y_outliers <- numeric(N)
y_outliers[1: (N-length(ind_outliers))] <- y[-ind_outliers] 
y_outliers[(N-length(ind_outliers) + 1): N] <- y[ind_outliers] + sigma*shift

y_data <- y_outliers

# Data list for Nimble
data_t_mixture <- list(y = y_data, N = N)

# Initial values for MCMC
initsFunction <- function() {
  list(mu = rnorm(K, 0, 1), tau = rgamma(K, 1, 1), nu = runif(K, 1, 10), 
       z = sample(1:K, N, replace = TRUE), w = rep(1/K, K))
}

# Constants and MCMC configuration
# Change alpha to 1 -> no dominant weight
constants <- list(K = K, alpha = rep(1, K)) 

# Build the model
t_mixture_model <- nimbleModel(t_mixture_code, data = data_t_mixture, 
                               inits = initsFunction(), constants = constants)

# Configuring MCMC (Metropolis-Hastings for nu)
mcmc_conf <- configureMCMC(t_mixture_model)

# Use Metropolis-Hastings for degrees of freedom (nu)
for (k in 1:K) {
  mcmc_conf$removeSampler(paste0("nu[", k, "]"))  # Remove default sampler for nu
  mcmc_conf$addSampler(paste0("nu[", k, "]"), type = "slice")  # Use slice sampler (or Metropolis)
}

# Add monitors to the MCMC configuration
mcmc_conf$addMonitors(c("mu", "tau", "nu", "w"))

# Build the MCMC sampler from the configuration
mcmc <- buildMCMC(mcmc_conf)

# Compile the model and MCMC
compiled_model <- compileNimble(t_mixture_model)
compiled_mcmc <- compileNimble(mcmc, project = t_mixture_model)

# Run MCMC (note: no 'monitors' argument here)
# Thin: how frequent samples are saved in MCMC process, ex: 5000 iter & 10 thin = 500 samples
n_iter <- 5000
samples_t_mixture <- runMCMC(compiled_mcmc, niter = n_iter, nburnin = 1000, thin = 1)
is.matrix(samples_t_mixture) #true
# Check the results
samples_matrix_t_mixture <- as.matrix(samples_t_mixture)
summary(samples_matrix_t_mixture)

head(samples_matrix_t_mixture)

w_samples_t <- samples_matrix_t_mixture[, grep("w", colnames(samples_matrix_t_mixture))]
mu_samples_t <- samples_matrix_t_mixture[, grep("mu", colnames(samples_matrix_t_mixture))]
tau_samples_t <- samples_matrix_t_mixture[, grep("tau", colnames(samples_matrix_t_mixture))]
df_samples_t <- samples_matrix_t_mixture[, grep("nu", colnames(samples_matrix_t_mixture))]
sigma2_samples_t <- 1 / tau_samples_t

#good fit criteria for t mix model
ghc3_t <- good_fit_criteria_t(y = y_data, P = w_samples_t, Mu = mu_samples_t, Sigma2 = sigma2_samples_t, df_samples = df_samples_t, nburn = 1000)
data.frame(LPML = ghc3_t$LPML, WAIC = ghc3_t$WAIC)

library(ggplot2)
head(samples_matrix_t_mixture)
# Assuming the posterior samples are stored in samples_matrix_t_mixture
# Extract posterior samples for the parameters
mu_samples <- samples_matrix_t_mixture[, grep("mu", colnames(samples_matrix_t_mixture))]
tau_samples <- samples_matrix_t_mixture[, grep("tau", colnames(samples_matrix_t_mixture))]
sigma2_samples <- 1/tau_samples
w_samples <- samples_matrix_t_mixture[, grep("w", colnames(samples_matrix_t_mixture))]
df_samples <- samples_matrix_t_mixture[, grep("nu", colnames(samples_matrix_t_mixture))]
# Create a grid of points over which to calculate the density
grid <- seq(min(y_data) - 1, max(y_data) + 1, length.out = 200)

# Initialize a matrix to store the densities
density <- matrix(0, nrow = nrow(mu_samples), ncol = length(grid))

# Calculate the density at each grid point using the posterior samples
for (g in 1:length(grid)) {
  for (k in 1:ncol(mu_samples)) {  # Loop over components
    # Compute density for each component and grid point
    density[, g] <- density[, g] + w_samples[, k] * dt((grid[g] - mu_samples[, k]) / sqrt(sigma2_samples[, k]), df = df_samples[,k]) / sqrt(sigma2_samples[, k])
  }
}

# Mean, Lwl, upd
mean_density <- apply(density, 2, mean)
lower_density <- apply(density, 2, quantile, prob = 0.025)
upper_density <- apply(density, 2, quantile, prob = 0.975)

# Create a data frame for the densities
density_df <- data.frame(grid = grid, 
                         mean_density = mean_density, 
                         lower_density = lower_density, 
                         upper_density = upper_density)

# Create a data frame for the histogram
df_hist <- data.frame(y = y_data)

# Plot the histogram and density estimates
ggplot() + 
  geom_histogram(data = df_hist, aes(x = y, y = after_stat(density)), bins = 40, alpha = 0.3, fill = "gray", color = "black") +
  geom_line(data = density_df, aes(x = grid, y = mean_density), color = "blue", size = 1) + 
  geom_ribbon(data = density_df, aes(x = grid, ymin = lower_density, ymax = upper_density), alpha = 0.3, fill = "dodgerblue") +
  xlab("y") + ylab("Density") + 
  ggtitle("Student-t Mixture Model Low df") + 
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5), text = element_text(size = 18))


ggplot() + 
  geom_histogram(data = df_hist, aes(x = y, y = after_stat(density)), bins = 40, alpha = 0.3, fill = "gray", color = "black") +
  geom_line(data = density_df, aes(x = grid, y = mean_density), color = "blue", size = 1) + 
  geom_ribbon(data = density_df, aes(x = grid, ymin = lower_density, ymax = upper_density), alpha = 0.3, fill = "dodgerblue") +
  geom_rug(data = df_hist, aes(x = y), sides = "b", color = "darkblue", alpha = 0.7) + 
  xlab("y") + 
  ylab("Density") + 
  ggtitle("Student-t Mixture Model Low df") + 
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5), text = element_text(size = 18))

#----------------------------------------------------------------#
#using gmm on y_data
#grid

set.seed(123)
fit_norm <- gmm(y = y_data, grid = grid, K = 20, amu = 0, b2mu = 0.01, asigma2 = 0.1,
            bsigma2 = 1, alpha = rep(1, 20), nsim = 5000, nburn = 1000)
# traceplot
plot(fit_norm$density[, random_index], type = "l", 
     main = paste("Gaussian mixture Trace Plot on Heavy Tail Data (10%) (K = 20)"),
     xlab = "Iteration", ylab = "Density")


#ess

# Calculate ESS for each grid point
ess_values_gmm <- apply(fit_norm$density, 2, coda::effectiveSize)

# Plotting box plot
boxplot(ess_values_gmm, main = "ESS across Grid Points for GMM (K = 20) on Heavy Tail Data (10%)",
        ylab = "Effective Sample Size (ESS)", col = "gray")
abline(h = 100, col = "red", lty = 2)  # Threshold line for reference

dens3m <- apply(fit_norm$density, 2, mean)
dens3l <- apply(fit_norm$density, 2, quantile, prob = 0.025)
dens3h <- apply(fit_norm$density, 2, quantile, prob = 0.975)

df_hist <- data.frame(y = y_data)
dfdens3 <- data.frame(dm = dens3m, dl = dens3l, dh = dens3h,
                      seqgrid = grid)
library(ggplot2)
#plot data, using sqrt data with normal mix model
ggplot(dfdens3, aes(x = seqgrid, y = dm)) + geom_line(size = 1) +
  geom_ribbon(data = dfdens3, aes(x = seqgrid, ymin = dl, ymax = dh),
              alpha = 0.3, fill = "dodgerblue1") + xlab("y") + ylab("Density") + geom_histogram(data = dfhist, aes(x = y,
                                                    y = after_stat(density)), alpha = 0.2, bins = 40, inherit.aes = FALSE,
                                 fill = "gray", colour = "black") + theme(text = element_text(size = 20)) +
  ggtitle("GMM on T mix Data, K = 10") + theme(plot.title = element_text(hjust = 0.5))

density <- fit_norm$density
mean_density <- apply(density, 2, mean)
lower_density <- apply(density, 2, quantile, prob = 0.025)
upper_density <- apply(density, 2, quantile, prob = 0.975)

# Create a data frame for the densities
density_df <- data.frame(grid = grid, 
                         mean_density = mean_density, 
                         lower_density = lower_density, 
                         upper_density = upper_density)
#updated plot
ggplot() + 
  geom_histogram(data = df_hist, aes(x = y, y = after_stat(density)), bins = 40, alpha = 0.3, fill = "gray", color = "black") +
  geom_line(data = density_df, aes(x = grid, y = mean_density), color = "blue", size = 1) + 
  geom_ribbon(data = density_df, aes(x = grid, ymin = lower_density, ymax = upper_density), alpha = 0.3, fill = "dodgerblue") +
  geom_rug(data = df_hist, aes(x = y), sides = "b", color = "darkblue", alpha = 0.7) + 
  xlab("y") + 
  ylab("Density") + 
  ggtitle("GMM on Data (10% Outliers) K = 20") + 
  theme_bw(base_size = 15) + theme(plot.title = element_text(hjust = 0.5, face="bold"),panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), text = element_text(size = 15))


density_50 <- fit_norm$density
samples_50 <- fit_norm$samples
# Extract posterior samples for weights, means, and variances
samples_matrix_50 <- as.matrix(samples_50)
w_samples <- samples_matrix_50[, grep("w", colnames(samples_matrix_50))]
mu_samples <- samples_matrix_50[, grep("mu", colnames(samples_matrix_50))]
tau_samples <- samples_matrix_50[, grep("tau", colnames(samples_matrix_50))]
sigma2_samples <- 1 / tau_samples
#good fit criteria for sqrt data using normal mix model
ghc3_norm <- good_fit_criteria(y = y_data, P = w_samples, Mu = mu_samples, Sigma2 = sigma2_samples,
                          nburn = 1000)
data.frame(LPML = ghc3_norm$LPML, WAIC = ghc3_norm$WAIC)



#using tmix_nimble

weights <- 1
df <- 3
mu <- 6
sd <- 2
set.seed(123)
# 

N <- 100
mu <- 3
sigma <- 1.15
y <- rnorm(N, mu, sigma)

K = 20
prop_outliers <- 0.05
shift <- 15
n_outliers <- round(N*prop_outliers)
ind_outliers<- sample(1:N, size = n_outliers)
y_outliers <- numeric(N)
y_outliers[1: (N-length(ind_outliers))] <- y[-ind_outliers] 
y_outliers[(N-length(ind_outliers) + 1): N] <- y[ind_outliers] + sigma*shift
y_data <- y_outliers

grid <- seq(min(y_data) - 1, max(y_data) + 1, length.out = 200)

#plot updated 10/1/2025
set.seed(123)
tmix_sample <- tmix_nimble(y_data, grid = grid, K = K, amu = 0, b2mu = 0.01,
                           asigma2 = 1, bsigma2 = 1, rate_nu = 0.1, alpha_dirichlet = rep(1,K),
                           nsim = 5000, nburn = 1000)

samples_t_mixture <- tmix_sample$samples
is.matrix(samples_t_mixture) #true
# Check the results
samples_matrix_t_mixture <- as.matrix(samples_t_mixture)
summary(samples_matrix_t_mixture)

head(samples_matrix_t_mixture)

w_samples_t <- samples_matrix_t_mixture[, grep("w", colnames(samples_matrix_t_mixture))]
mu_samples_t <- samples_matrix_t_mixture[, grep("mu", colnames(samples_matrix_t_mixture))]
tau_samples_t <- samples_matrix_t_mixture[, grep("tau", colnames(samples_matrix_t_mixture))]
df_samples_t <- samples_matrix_t_mixture[, grep("nu", colnames(samples_matrix_t_mixture))]
sigma2_samples_t <- 1 / tau_samples_t

#good fit criteria for t mix model
ghc3_t <- good_fit_criteria_t(y = y_data, P = w_samples_t, Mu = mu_samples_t, Sigma2 = sigma2_samples_t, df_samples = df_samples_t, nburn = 1000)
data.frame(LPML = ghc3_t$LPML, WAIC = ghc3_t$WAIC)

library(ggplot2)
head(samples_matrix_t_mixture)
# Assuming the posterior samples are stored in samples_matrix_t_mixture
# Extract posterior samples for the parameters
mu_samples <- samples_matrix_t_mixture[, grep("mu", colnames(samples_matrix_t_mixture))]
tau_samples <- samples_matrix_t_mixture[, grep("tau", colnames(samples_matrix_t_mixture))]
sigma2_samples <- 1/tau_samples
w_samples <- samples_matrix_t_mixture[, grep("w", colnames(samples_matrix_t_mixture))]
df_samples <- samples_matrix_t_mixture[, grep("nu", colnames(samples_matrix_t_mixture))]
# Create a grid of points over which to calculate the density
grid <- seq(min(y_data) - 1, max(y_data) + 1, length.out = 200)

# Initialize a matrix to store the densities
density <- matrix(0, nrow = nrow(mu_samples), ncol = length(grid))

# Calculate the density at each grid point using the posterior samples
for (g in 1:length(grid)) {
  for (k in 1:ncol(mu_samples)) {  # Loop over components
    # Compute density for each component and grid point
    density[, g] <- density[, g] + w_samples[, k] * dt((grid[g] - mu_samples[, k]) / sqrt(sigma2_samples[, k]), df = df_samples[,k]) / sqrt(sigma2_samples[, k])
  }
}

# Mean, Lwl, upd
mean_density <- apply(density, 2, mean)
lower_density <- apply(density, 2, quantile, prob = 0.025)
upper_density <- apply(density, 2, quantile, prob = 0.975)

# Create a data frame for the densities
density_df <- data.frame(grid = grid, 
                         mean_density = mean_density, 
                         lower_density = lower_density, 
                         upper_density = upper_density)

# Create a data frame for the histogram
df_hist <- data.frame(y = y_data)

# Plot the histogram and density estimates
# ggplot() + 
#   geom_histogram(data = df_hist, aes(x = y, y = after_stat(density)), bins = 40, alpha = 0.3, fill = "gray", color = "black") +
#   geom_line(data = density_df, aes(x = grid, y = mean_density), color = "blue", size = 1) + 
#   geom_ribbon(data = density_df, aes(x = grid, ymin = lower_density, ymax = upper_density), alpha = 0.3, fill = "dodgerblue") +
#   xlab("y") + ylab("Density") + 
#   ggtitle("Student-t Mixture Model Low df") + 
#   theme_minimal() + 
#   theme(plot.title = element_text(hjust = 0.5), text = element_text(size = 18))


ggplot() + 
  geom_histogram(data = df_hist, aes(x = y, y = after_stat(density)), bins = 40, alpha = 0.3, fill = "gray", color = "black") +
  geom_line(data = density_df, aes(x = grid, y = mean_density), color = "blue", size = 1) + 
  geom_ribbon(data = density_df, aes(x = grid, ymin = lower_density, ymax = upper_density), alpha = 0.3, fill = "dodgerblue") +
  geom_rug(data = df_hist, aes(x = y), sides = "b", color = "darkblue", alpha = 0.7) + 
  xlab("y") + 
  ylab("Density") + 
  ggtitle("Student-t Mixture Model on Heavy Tail Data, K = 10") + 
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5), text = element_text(size = 18))

#updated plot
density <- tmix_sample$density
mean_density <- apply(density, 2, mean)
lower_density <- apply(density, 2, quantile, prob = 0.025)
upper_density <- apply(density, 2, quantile, prob = 0.975)

# Create a data frame for the densities
density_df <- data.frame(grid = grid, 
                         mean_density = mean_density, 
                         lower_density = lower_density, 
                         upper_density = upper_density)
#updated plot
ggplot() + 
  geom_histogram(data = df_hist, aes(x = y, y = after_stat(density)), bins = 40, alpha = 0.3, fill = "gray", color = "black") +
  geom_line(data = density_df, aes(x = grid, y = mean_density), color = "blue", size = 1) + 
  geom_ribbon(data = density_df, aes(x = grid, ymin = lower_density, ymax = upper_density), alpha = 0.3, fill = "dodgerblue") +
  geom_rug(data = df_hist, aes(x = y), sides = "b", color = "darkblue", alpha = 0.7) + 
  xlab("y") + 
  ylab("Density") + 
  ggtitle("t Mix Model on Data (10% Outliers) K = 20") + 
  theme_bw(base_size = 15) + theme(plot.title = element_text(hjust = 0.5, face="bold"),panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), text = element_text(size = 15))





#---------------------------------------------------------------------------#
#using more outlier data
source("finite_mixture.R")
set.seed(123)
# Parameters for the main normal distribution
N <- 100
mu <- 3
sigma <- 1.15

# Generate main normal data
y <- rnorm(N, mu, sigma)

# Proportion of outliers and amount of shift for outliers
prop_outliers <- 0.1  # Higher proportion of outliers for heavier tails
shift <- 20           # Larger shift for more extreme outliers
t_df <- 3             # Degrees of freedom for t-distribution (heavier tails)

# Determine number of outliers
n_outliers <- round(N * prop_outliers)

# Select indices for outliers
ind_outliers <- sample(1:N, size = n_outliers)

# Initialize outlier-adjusted data
y_outliers <- numeric(N)

# Assign non-outlier data
y_outliers[1:(N - length(ind_outliers))] <- y[-ind_outliers]

# Assign outliers using a t-distribution for heavy tails and add shift
y_outliers[(N - length(ind_outliers) + 1):N] <- rt(n_outliers, df = t_df) * sigma + mu + shift

# Final data with outliers and heavier tails
y_data <- y_outliers

K = 20

grid <- seq(min(y_data) - 1, max(y_data) + 1, length.out = 200)

tmix_sample <- tmix_nimble(y_data, grid = grid, K = K, amu = 0, b2mu = 0.01,
                           asigma2 = 1, bsigma2 = 1, rate_nu = 0.1, alpha_dirichlet = rep(1,K),
                           nsim = 5000, nburn = 1000)

samples_t_mixture <- tmix_sample$samples
sample_t_dens <- tmix_sample$density
#traceplots
set.seed(123)
random_index <- sample(1:ncol(sample_t_dens), 1)

random_index

plot(sample_t_dens[, random_index], type = "l", 
     main = paste("t mixture Trace Plot on Heavy Tail Data (10%) (K = 20)"),
     xlab = "Iteration", ylab = "Density")

#ess plots
# Calculate ESS for each grid point
ess_values <- apply(sample_t_dens, 2, coda::effectiveSize)

# Plotting box plot
boxplot(ess_values, main = "ESS across Grid Points for t mix (K = 20) on Heavy Tail Data (10%)",
        ylab = "Effective Sample Size (ESS)", col = "gray")
abline(h = 100, col = "red", lty = 2)  # Threshold line for reference

is.matrix(samples_t_mixture) #true
# Check the results
samples_matrix_t_mixture <- as.matrix(samples_t_mixture)
summary(samples_matrix_t_mixture)

head(samples_matrix_t_mixture)

w_samples_t <- samples_matrix_t_mixture[, grep("w", colnames(samples_matrix_t_mixture))]
mu_samples_t <- samples_matrix_t_mixture[, grep("mu", colnames(samples_matrix_t_mixture))]
tau_samples_t <- samples_matrix_t_mixture[, grep("tau", colnames(samples_matrix_t_mixture))]
df_samples_t <- samples_matrix_t_mixture[, grep("nu", colnames(samples_matrix_t_mixture))]
sigma2_samples_t <- 1 / tau_samples_t

#good fit criteria for t mix model
ghc3_t <- good_fit_criteria_t(y = y_data, P = w_samples_t, Mu = mu_samples_t, Sigma2 = sigma2_samples_t, df_samples = df_samples_t, nburn = 1000)
data.frame(LPML = ghc3_t$LPML, WAIC = ghc3_t$WAIC)

library(ggplot2)
head(samples_matrix_t_mixture)
# Assuming the posterior samples are stored in samples_matrix_t_mixture
# Extract posterior samples for the parameters
mu_samples <- samples_matrix_t_mixture[, grep("mu", colnames(samples_matrix_t_mixture))]
tau_samples <- samples_matrix_t_mixture[, grep("tau", colnames(samples_matrix_t_mixture))]
sigma2_samples <- 1/tau_samples
w_samples <- samples_matrix_t_mixture[, grep("w", colnames(samples_matrix_t_mixture))]
df_samples <- samples_matrix_t_mixture[, grep("nu", colnames(samples_matrix_t_mixture))]
# Create a grid of points over which to calculate the density
grid <- seq(min(y_data) - 1, max(y_data) + 1, length.out = 200)

# Initialize a matrix to store the densities
density <- matrix(0, nrow = nrow(mu_samples), ncol = length(grid))

# Calculate the density at each grid point using the posterior samples
for (g in 1:length(grid)) {
  for (k in 1:ncol(mu_samples)) {  # Loop over components
    # Compute density for each component and grid point
    density[, g] <- density[, g] + w_samples[, k] * dt((grid[g] - mu_samples[, k]) / sqrt(sigma2_samples[, k]), df = df_samples[,k]) / sqrt(sigma2_samples[, k])
  }
}

# Mean, Lwl, upd
mean_density <- apply(density, 2, mean)
lower_density <- apply(density, 2, quantile, prob = 0.025)
upper_density <- apply(density, 2, quantile, prob = 0.975)

# Create a data frame for the densities
density_df <- data.frame(grid = grid, 
                         mean_density = mean_density, 
                         lower_density = lower_density, 
                         upper_density = upper_density)

# Create a data frame for the histogram
df_hist <- data.frame(y = y_data)

# Plot the histogram and density estimates
# ggplot() + 
#   geom_histogram(data = df_hist, aes(x = y, y = after_stat(density)), bins = 40, alpha = 0.3, fill = "gray", color = "black") +
#   geom_line(data = density_df, aes(x = grid, y = mean_density), color = "blue", size = 1) + 
#   geom_ribbon(data = density_df, aes(x = grid, ymin = lower_density, ymax = upper_density), alpha = 0.3, fill = "dodgerblue") +
#   xlab("y") + ylab("Density") + 
#   ggtitle("Student-t Mixture Model Low df") + 
#   theme_minimal() + 
#   theme(plot.title = element_text(hjust = 0.5), text = element_text(size = 18))


ggplot() + 
  geom_histogram(data = df_hist, aes(x = y, y = after_stat(density)), bins = 40, alpha = 0.3, fill = "gray", color = "black") +
  geom_line(data = density_df, aes(x = grid, y = mean_density), color = "blue", size = 1) + 
  geom_ribbon(data = density_df, aes(x = grid, ymin = lower_density, ymax = upper_density), alpha = 0.3, fill = "dodgerblue") +
  geom_rug(data = df_hist, aes(x = y), sides = "b", color = "darkblue", alpha = 0.7) + 
  xlab("y") + 
  ylab("Density") + 
  ggtitle("Student-t Mixture Model on Heavy Tail Data, K = 10") + 
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5), text = element_text(size = 18))

#----------------------------------------------------------------------#

# repeat experiment 20 times
source("finite_mixture.R")
set.seed(123)
# Parameters for the main normal distribution
N <- 100
mu <- 3
sigma <- 1.15
prop_outliers <- 0.05  # Higher proportion of outliers for heavier tails
shift <- 20           # Larger shift for more extreme outliers
t_df <- 3             # Degrees of freedom for t-distribution (heavier tails)
num_datasets <- 20    # Number of datasets to generate

# Initialize a list to store each dataset
datasets <- vector("list", num_datasets)

# Generate 20 datasets with outliers and store them in the list
for (i in 1:num_datasets) {
  # Generate the main normal data
  y <- rnorm(N, mu, sigma)
  
  # Determine the number of outliers
  n_outliers <- round(N * prop_outliers)
  
  # Select indices for outliers randomly
  ind_outliers <- sample(1:N, size = n_outliers)
  
  # Initialize outlier-adjusted data
  y_outliers <- numeric(N)
  
  # Assign non-outlier data
  y_outliers[1:(N - length(ind_outliers))] <- y[-ind_outliers]
  
  # Assign outliers using a t-distribution for heavy tails and add shift
  y_outliers[(N - length(ind_outliers) + 1):N] <- rt(n_outliers, df = t_df) * sigma + mu + shift
  
  # Store the generated dataset in the list
  datasets[[i]] <- y_outliers
}

# looping 20 times.
# Set parameters
num_experiments <- length(datasets)  # Number of datasets (20 in this case)
K <- 20  # Number of mixture components

# head(datasets)
# Initialize vectors to store WAIC and LPML values for each experiment
waic_values <- numeric(num_experiments)
lpml_values <- numeric(num_experiments)

# Loop through each dataset to fit the t-mixture model and calculate good fit criteria
for (i in 1:num_experiments) {
  grid <- seq(min(datasets[[i]]) - 1, max(datasets[[i]]) + 1, len = 200) 
  # Fit the t-mixture model on the current dataset
  tmix_sample <- tmix_nimble(datasets[[i]], grid = grid, K = K, amu = 0, b2mu = 0.01,
                             asigma2 = 1, bsigma2 = 1, rate_nu = 0.1, alpha_dirichlet = rep(0.1, K),
                             nsim = 5000, nburn = 1000)
  
  # Extract posterior samples
  samples_t_mixture <- tmix_sample$samples
  samples_matrix_t_mixture <- as.matrix(samples_t_mixture)
  
  # Extract weights, means, variances, and degrees of freedom samples
  w_samples_t <- samples_matrix_t_mixture[, grep("w", colnames(samples_matrix_t_mixture))]
  mu_samples_t <- samples_matrix_t_mixture[, grep("mu", colnames(samples_matrix_t_mixture))]
  tau_samples_t <- samples_matrix_t_mixture[, grep("tau", colnames(samples_matrix_t_mixture))]
  df_samples_t <- samples_matrix_t_mixture[, grep("nu", colnames(samples_matrix_t_mixture))]
  sigma2_samples_t <- 1 / tau_samples_t
  
  # Calculate WAIC and LPML for the current experiment
  ghc_t <- good_fit_criteria_t(y = datasets[[i]], P = w_samples_t, Mu = mu_samples_t,
                               Sigma2 = sigma2_samples_t, df_samples = df_samples_t, nburn = 1000)
  
  # Store the WAIC and LPML values
  waic_values[i] <- ghc_t$WAIC
  lpml_values[i] <- ghc_t$LPML
}

# Calculate the average WAIC and LPML across all experiments
average_waic <- mean(waic_values)
average_lpml <- mean(lpml_values)

# Print results
data.frame(Average_WAIC = average_waic, Average_LPML = average_lpml)


num_experiments <- length(datasets)  # Number of datasets (20 in this case)
K <- 20  # Number of mixture components
# Initialize vectors to store WAIC and LPML values for each experiment
waic_values2 <- numeric(num_experiments)
lpml_values2 <- numeric(num_experiments)

# Loop through each dataset to fit the Gaussian mixture model and calculate good fit criteria
for (i in 1:num_experiments) {
  grid <- seq(min(datasets[[i]]) - 1, max(datasets[[i]]) + 1, len = 200)
  # Fit the Gaussian mixture model on the current dataset
  fit_norm <- gmm(y = datasets[[i]], grid = grid, K = K, amu = 0, b2mu = 100, 
                  asigma2 = 0.1, bsigma2 = 1, alpha = rep(1, K), nsim = 5000, nburn = 1000)
  
  # Extract posterior samples for weights, means, and variances
  samples_norm <- fit_norm$samples
  samples_matrix_norm <- as.matrix(samples_norm)
  
  # Extract weights, means, and variances
  w_samples <- samples_matrix_norm[, grep("w", colnames(samples_matrix_norm))]
  mu_samples <- samples_matrix_norm[, grep("mu", colnames(samples_matrix_norm))]
  tau_samples <- samples_matrix_norm[, grep("tau", colnames(samples_matrix_norm))]
  sigma2_samples <- 1 / tau_samples
  
  # Calculate WAIC and LPML for the current experiment
  ghc_norm <- good_fit_criteria(y = datasets[[i]], P = w_samples, Mu = mu_samples, 
                                Sigma2 = sigma2_samples, nburn = 1000)
  
  # Store the WAIC and LPML values
  waic_values2[i] <- ghc_norm$WAIC
  lpml_values2[i] <- ghc_norm$LPML
}

# Calculate the average WAIC and LPML across all experiments
average_waic2 <- mean(waic_values2)
average_lpml2 <- mean(lpml_values2)

# Print results
data.frame(Average_WAIC = average_waic2, Average_LPML = average_lpml2)


#------------------------------------------------------------------------#
# Repeating experiments for GMM
source("finite_mixture.R")
set.seed(123)
# Parameters for the main normal distribution
N <- 500
mu <- 3
sigma <- 1.15
prop_outliers <- 0.1  # Higher proportion of outliers for heavier tails
shift <- 20           # Larger shift for more extreme outliers
t_df <- 3             # Degrees of freedom for t-distribution (heavier tails)
num_datasets <- 20    # Number of datasets to generate

# Initialize a list to store each dataset
datasets <- vector("list", num_datasets)

# Generate 20 datasets with outliers and store them in the list
for (i in 1:num_datasets) {
  # Generate the main normal data
  y <- rnorm(N, mu, sigma)
  
  # Determine the number of outliers
  n_outliers <- round(N * prop_outliers)
  
  # Select indices for outliers randomly
  ind_outliers <- sample(1:N, size = n_outliers)
  
  # Initialize outlier-adjusted data
  y_outliers <- numeric(N)
  
  # Assign non-outlier data
  y_outliers[1:(N - length(ind_outliers))] <- y[-ind_outliers]
  
  # Assign outliers using a t-distribution for heavy tails and add shift
  y_outliers[(N - length(ind_outliers) + 1):N] <- rt(n_outliers, df = t_df) * sigma + mu + shift
  
  # Store the generated dataset in the list
  datasets[[i]] <- y_outliers
}
# Set parameters

num_experiments <- length(datasets)  # Number of datasets (20 in this case)
K <- 20  # Number of mixture components
# Initialize vectors to store WAIC and LPML values for each experiment
waic_values2 <- numeric(num_experiments)
lpml_values2 <- numeric(num_experiments)

# Loop through each dataset to fit the Gaussian mixture model and calculate good fit criteria
for (i in 1:num_experiments) {
  grid <- seq(min(datasets[[i]]) - 1, max(datasets[[i]]) + 1, len = 200)
  # Fit the Gaussian mixture model on the current dataset
  fit_norm <- gmm(y = datasets[[i]], grid = grid, K = K, amu = 0, b2mu = 100, 
                  asigma2 = 0.1, bsigma2 = 1, alpha = rep(1, K), nsim = 5000, nburn = 1000)
  
  # Extract posterior samples for weights, means, and variances
  samples_norm <- fit_norm$samples
  samples_matrix_norm <- as.matrix(samples_norm)
  
  # Extract weights, means, and variances
  w_samples <- samples_matrix_norm[, grep("w", colnames(samples_matrix_norm))]
  mu_samples <- samples_matrix_norm[, grep("mu", colnames(samples_matrix_norm))]
  tau_samples <- samples_matrix_norm[, grep("tau", colnames(samples_matrix_norm))]
  sigma2_samples <- 1 / tau_samples
  
  # Calculate WAIC and LPML for the current experiment
  ghc_norm <- good_fit_criteria(y = datasets[[i]], P = w_samples, Mu = mu_samples, 
                                Sigma2 = sigma2_samples, nburn = 1000)
  
  # Store the WAIC and LPML values
  waic_values2[i] <- ghc_norm$WAIC
  lpml_values2[i] <- ghc_norm$LPML
}

# Calculate the average WAIC and LPML across all experiments
average_waic2 <- mean(waic_values2)
average_lpml2 <- mean(lpml_values2)

# Print results
data.frame(Average_WAIC = average_waic2, Average_LPML = average_lpml2)
